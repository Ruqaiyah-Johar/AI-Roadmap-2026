{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6ceef2-8e7b-462b-b37e-28c6e10dd7fa",
   "metadata": {},
   "source": [
    "### Logistic Regression on Breast Cancer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ad8ea-8753-4a24-b680-a9a39493ce4c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "This notebook uses the breast cancer dataset from scikit-learn to build a binary classifier with logistic regression implemented from scratch using Python loops instead of vectorized NumPy code. It covers data loading, basic feature standardization, manual implementation of cost, gradient, and prediction functions, gradient descent training, and evaluation of train/test accuracy as a first practical ML project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ee290-4a4f-48a2-810b-169049dabbfe",
   "metadata": {},
   "source": [
    "### Load dataset (scikit learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eba1a18-b66d-43d3-99a9-14d051fdb36e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d65aaf-b204-416b-a7e1-48e2f97fad0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: (569, 30)\n",
      "shape of y: (569,)\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "x = cancer.data\n",
    "y = cancer.target\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dc9c1-af41-418c-a180-06c4e673870f",
   "metadata": {},
   "source": [
    "### Standardization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4a8abd-2a76-4722-99d7-a92f0558152f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_norm mean (approx): [-3.16286735e-15 -6.53060890e-15 -7.07889127e-16 -8.79983452e-16\n",
      "  6.13217737e-15]\n",
      "x_norm std (approx): [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# simple standardization: (x - mean) / std\n",
    "x_mean = np.mean(x, axis=0)\n",
    "x_std  = np.std(x, axis=0)\n",
    "x_norm = (x - x_mean) / x_std\n",
    "\n",
    "print(\"x_norm mean (approx):\", np.mean(x_norm, axis=0)[:5])\n",
    "print(\"x_norm std (approx):\", np.std(x_norm, axis=0)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60ed9761-f0fa-4ed0-afbe-1a16e8304753",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (455, 30) (455,)\n",
      "Test shape: (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "m = x_norm.shape[0]\n",
    "train_size = int(0.8 * m)\n",
    "\n",
    "x_train = x_norm[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x_norm[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e84b-2dde-4c7e-9878-088507f0bb2e",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression - loop based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d819f1f-4090-4275-8e12-522f1b992bad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    m, n = x.shape\n",
    "    #print(\"DEBUG: m =\", m, \"len(y) =\", len(y))\n",
    "    dj_dw = np.zeros_like(w)\n",
    "    dj_db = 0.0\n",
    "    for i in range(m):\n",
    "        z_wb = np.dot(x[i], w) + b\n",
    "        f_wb = sigmoid(z_wb)\n",
    "        err = f_wb - y[i]\n",
    "        dj_db += err\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err * x[i][j]\n",
    "    dj_db /= m\n",
    "    dj_dw /= m\n",
    "    return dj_db, dj_dw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8efc0b30-c183-458b-8eef-ad0af215eb84",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dj_db, dj_dw = compute_gradient(x_train, y_train, w, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6cae09-e840-4438-9e58-97019e5601bb",
   "metadata": {},
   "source": [
    "### Training on gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9103f337-aa38-498c-b252-3ef851656ae3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,)\n",
      "Iter    0: cost 0.5174\n",
      "Iter  100: cost 0.0985\n",
      "Iter  200: cost 0.0813\n",
      "Iter  300: cost 0.0739\n",
      "Iter  400: cost 0.0696\n",
      "Iter  500: cost 0.0667\n",
      "Iter  600: cost 0.0646\n",
      "Iter  700: cost 0.0629\n",
      "Iter  800: cost 0.0615\n",
      "Iter  900: cost 0.0604\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# training loop\n",
    "m, n = x_train.shape\n",
    "w = np.zeros(n)\n",
    "b = 0.0\n",
    "\n",
    "alpha = 0.1\n",
    "num_iters = 1000\n",
    "\n",
    "for it in range(num_iters):\n",
    "    dj_db, dj_dw = compute_gradient(x_train, y_train, w, b)\n",
    "    w = w - alpha * dj_dw\n",
    "    b = b - alpha * dj_db\n",
    "    if it % 100 == 0:\n",
    "        cost = compute_cost(x_train, y_train, w, b)\n",
    "        print(f\"Iter {it:4d}: cost {cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a811e88-137d-4372-a895-fa5424445e3c",
   "metadata": {},
   "source": [
    "### Evaluating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7575af2-a4b8-44f1-bd2c-e03728519e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 98.24%\n"
     ]
    }
   ],
   "source": [
    "p_train = predict(x_train, w, b)\n",
    "train_acc = np.mean(p_train == y_train) * 100\n",
    "print(f\"Train accuracy: {train_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7084f4e-0efc-4eda-987f-87ceff8ccc2f",
   "metadata": {},
   "source": [
    "### The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26830481-22b1-4628-bf6a-f558c0cef474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
